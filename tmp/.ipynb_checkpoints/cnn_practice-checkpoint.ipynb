{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-ab7b3ff79b6d>:88: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 0.5787333\n",
      "Test Accuracy: 0.5625\n",
      "Tensor(\"Mean_2:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 0.99985\n",
      "Test Accuracy: 0.9991\n",
      "Tensor(\"Mean_3:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 0.99985\n",
      "Test Accuracy: 0.9991\n",
      "Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 0.99985\n",
      "Test Accuracy: 0.9991\n",
      "Tensor(\"Mean_5:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 0.99985\n",
      "Test Accuracy: 0.9991\n",
      "Tensor(\"Mean_6:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 0.99985\n",
      "Test Accuracy: 0.9991\n",
      "Tensor(\"Mean_7:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 0.99985\n",
      "Test Accuracy: 0.9991\n",
      "Tensor(\"Mean_8:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 0.99985\n",
      "Test Accuracy: 0.9991\n",
      "Tensor(\"Mean_9:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 0.99985\n",
      "Test Accuracy: 0.9991\n",
      "Tensor(\"Mean_10:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 0.99985\n",
      "Test Accuracy: 0.9991\n",
      "Tensor(\"Mean_11:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 0.99985\n",
      "Test Accuracy: 0.9991\n",
      "Tensor(\"Mean_12:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 0.99985\n",
      "Test Accuracy: 0.9991\n",
      "Tensor(\"Mean_13:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/shumpei/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-ab7b3ff79b6d>\", line 107, in <module>\n",
      "    train_accuracy = accuracy.eval({X: train_X, Y: train_Y})\n",
      "  File \"/Users/shumpei/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 711, in eval\n",
      "    return _eval_using_default_session(self, feed_dict, self.graph, session)\n",
      "  File \"/Users/shumpei/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 5155, in _eval_using_default_session\n",
      "    return session.run(tensors, feed_dict)\n",
      "  File \"/Users/shumpei/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 887, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/Users/shumpei/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1079, in _run\n",
      "    np_val = np.asarray(subfeed_val, dtype=subfeed_dtype)\n",
      "  File \"/Users/shumpei/anaconda/lib/python3.6/site-packages/numpy/core/numeric.py\", line 501, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/shumpei/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/shumpei/anaconda/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/shumpei/anaconda/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/shumpei/anaconda/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/shumpei/anaconda/lib/python3.6/inspect.py\", line 1480, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/shumpei/anaconda/lib/python3.6/inspect.py\", line 1438, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/shumpei/anaconda/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/shumpei/anaconda/lib/python3.6/inspect.py\", line 729, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "\n",
    "def create_placeholder(n0_h, n0_w, n0_c, output_dim):\n",
    "# create placeholder of input Matrix\n",
    "    X = tf.placeholder(dtype=tf.float32, name=\"X\", shape=(None, n0_h, n0_w, n0_c))\n",
    "    Y = tf.placeholder(dtype=tf.float32, name=\"Y\", shape=(None, output_dim))\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "# initialize parameter \n",
    "def initialize_parameter(hparameters):\n",
    "    conv_f1 = hparameters[\"conv_f1\"]\n",
    "    conv_f2 = hparameters[\"conv_f2\"]\n",
    "    n1_c = hparameters[\"n1_c\"]\n",
    "    n2_c = hparameters[\"n2_c\"]\n",
    "    W1 = tf.get_variable(dtype=tf.float32, name=\"W1\", initializer=tf.contrib.layers.xavier_initializer(), shape=(conv_f1, conv_f1, n0_c, n1_c))\n",
    "    W2 = tf.get_variable(dtype=tf.float32, name=\"W2\", initializer=tf.contrib.layers.xavier_initializer(), shape=(conv_f2, conv_f2, n1_c, n2_c))\n",
    "    b1 = tf.get_variable(dtype=tf.float32, name=\"b1\", initializer=tf.zeros_initializer(), shape=(1,1 ,1, n1_c))\n",
    "    b2 = tf.get_variable(dtype=tf.float32, name=\"b2\", initializer=tf.zeros_initializer(), shape=(1, 1, 1, n2_c))\n",
    "    return W1, W2, b1, b2\n",
    "\n",
    "\n",
    "def forward_propagation(hparameters, X, W1, W2, output_dim):\n",
    "# forward propagation\n",
    "\n",
    "    # convolution\n",
    "    conv_s1 = hparameters[\"conv_s1\"]\n",
    "    pool_s1 = hparameters[\"pool_s1\"]\n",
    "    pool_f1 =  hparameters[\"pool_f1\"]\n",
    "\n",
    "    conv_s2 = hparameters[\"conv_s2\"]\n",
    "    pool_s2 = hparameters[\"pool_s2\"]\n",
    "    pool_f2 =  hparameters[\"pool_f2\"]\n",
    "\n",
    "    Z1 = tf.add(tf.nn.conv2d(filter=W1, input=X, name=\"Z1\", strides=[1, conv_s1, conv_s1, 1], padding=\"SAME\"), b1)\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    P1 = tf.nn.max_pool(A1, ksize=(1, pool_f1, pool_f1, 1), strides=[1, pool_s1, pool_s1, 1], padding=\"SAME\")\n",
    "\n",
    "    Z2 = tf.add(tf.nn.conv2d(filter=W2, input=P1, name=\"Z2\", strides=[1, conv_s2, conv_s2, 1], padding=\"SAME\"), b2)\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    P2 = tf.nn.max_pool(A2, ksize=(1, pool_f2, pool_f2, 1), strides=[1, pool_s2, pool_s2, 1], padding=\"SAME\")\n",
    "    \n",
    "    # flatten\n",
    "    P2 = tf.contrib.layers.flatten(inputs=P2)\n",
    "    \n",
    "    S = tf.contrib.layers.fully_connected(inputs=P2, num_outputs=output_dim)\n",
    "\n",
    "    return S\n",
    "\n",
    "# prepare dataset \n",
    "train,test = load_data()\n",
    "train_X, train_Y = train\n",
    "test_X, test_Y = test\n",
    "train_X = train_X.reshape((train_X.shape[0], train_X.shape[1], train_X.shape[2], 1))\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[1], test_X.shape[2], 1))\n",
    "n_labels = np.unique(train_Y)\n",
    "train_Y = np.eye(train_Y.shape[0])[n_labels].T\n",
    "test_Y = np.eye(test_Y.shape[0])[n_labels].T\n",
    "\n",
    "assert(train_X.shape[1] == test_X.shape[1])\n",
    "assert(train_X.shape[0] == train_Y.shape[0])\n",
    "\n",
    "# paramter setting \n",
    "n0_h = train_X.shape[1]\n",
    "n0_w = train_X.shape[2]\n",
    "n0_c = train_X.shape[3]\n",
    "output_dim = train_Y.shape[1]\n",
    "hparameters = {\"conv_f1\": 2, \"conv_s1\":1,\"pool_f1\":2, \"pool_s1\":1, \"n1_c\":8,\n",
    "               \"conv_f2\": 4,\"conv_s2\":2,\"pool_f2\":4, \"pool_s2\":2, \"n2_c\":16}\n",
    "iteration_num = 100\n",
    "\n",
    "# reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# create placeholder for input data\n",
    "X, Y = create_placeholder(n0_h, n0_w, n0_c, output_dim)\n",
    "\n",
    "# initialize parameter\n",
    "W1, W2, b1, b2 = initialize_parameter(hparameters)\n",
    "\n",
    "# forward propagation\n",
    "S = forward_propagation(hparameters, X, W1, W2, output_dim)\n",
    "\n",
    "# compute cost \n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=S, labels=Y))\n",
    "\n",
    "# backpropagation\n",
    "optimize = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# initialize\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "costs = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(iteration_num):\n",
    "        _, temp_cost = sess.run([optimize, cost], feed_dict={X:train_X, Y:train_Y})\n",
    "        \n",
    "        \n",
    "        predict_op = tf.argmax(S, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        train_accuracy = accuracy.eval({X: train_X, Y: train_Y})\n",
    "        test_accuracy = accuracy.eval({X: test_X, Y: test_Y})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "        costs.append(temp_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
